# ADR-003: Cache Architecture

**Date**: 2026-01-11  
**Status**: âœ… Accepted  
**Deciders**: Mathieu Chambaud, Mary (Business Analyst)

---

## Context

Le Fraud Detection Engine doit Ãªtre **ultra-rapide** (target: < 250ms P95) pour respecter le timeout webhook Stripe de 2s.

**DonnÃ©es frÃ©quemment lues** (hot paths) :
- âœ… Custom Rules (changent rarement, lus Ã  chaque transaction)
- âœ… Customer Trust Scores (changent peu, lus trÃ¨s souvent)
- âœ… Whitelist/Blacklist (changent peu, DOIVENT Ãªtre ultra-rapides pour early exit)
- âœ… Fraud Rules Config (quasi-statiques)
- âŒ Velocity Metrics (NE PAS cacher, trop volatiles)

**Performance actuelle sans cache** :
- DB query custom rules : ~40ms
- DB query customer scores : ~30ms
- DB query whitelist : ~50ms
- **Total context building : ~200ms** (trop lent!)

**Target avec cache** :
- < 10ms pour context building
- Hit rate > 80%

**Contrainte** : Vercel Serverless = instances Ã©phÃ©mÃ¨res (pas de mÃ©moire persistante entre requÃªtes)

---

## Decision

**Nous choisissons : Dual-Layer Cache (In-Memory + Redis)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     SERVERLESS FUNCTION             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  L1: In-Memory (Map)         â”‚   â”‚ â† < 1ms (90% hits after warm)
â”‚  â”‚  TTL: 60s                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚ miss                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  L2: Upstash Redis           â”‚   â”‚ â† 5-10ms (9% hits)
â”‚  â”‚  TTL: 5-15min                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚ miss                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  PostgreSQL     â”‚ â† 50-100ms (1% miss)
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation** :
```typescript
// packages/fraud-engine/src/services/cache.service.ts
class DualLayerCache {
  private memoryCache = new Map<string, CachedItem>();
  private redis: Redis; // Upstash

  async get<T>(key: string): Promise<T | null> {
    // L1: In-Memory (< 1ms)
    const memCached = this.memoryCache.get(key);
    if (memCached && memCached.expiresAt > Date.now()) {
      this.metrics.l1Hits++;
      return memCached.value as T;
    }

    // L2: Redis (5-10ms)
    const redisCached = await this.redis.get(key);
    if (redisCached) {
      this.metrics.l2Hits++;
      // Warm L1
      this.memoryCache.set(key, {
        value: redisCached,
        expiresAt: Date.now() + 60_000, // 60s
      });
      return redisCached as T;
    }

    this.metrics.misses++;
    return null;
  }

  async set<T>(key: string, value: T, ttl: number): Promise<void> {
    // Set both layers
    this.memoryCache.set(key, {
      value,
      expiresAt: Date.now() + 60_000, // L1: 60s
    });
    await this.redis.set(key, value, { ex: ttl }); // L2: configurable
  }

  async invalidate(pattern: string): Promise<void> {
    // Invalidate L1
    for (const [key] of this.memoryCache) {
      if (key.includes(pattern)) {
        this.memoryCache.delete(key);
      }
    }
    // Invalidate L2 (Redis pattern scan)
    const keys = await this.redis.keys(`*${pattern}*`);
    if (keys.length > 0) {
      await this.redis.del(...keys);
    }
  }
}
```

**Cache TTLs Strategy** :
```typescript
const CACHE_CONFIG = {
  customRules: { ttl: 60, layer: 'L1+L2' },        // 1 min
  customerScores: { ttl: 300, layer: 'L2' },       // 5 min
  fraudRules: { ttl: 900, layer: 'L1+L2' },        // 15 min
  whitelist: { ttl: 300, layer: 'L1+L2' },         // 5 min (critical)
  blacklist: { ttl: 300, layer: 'L1+L2' },         // 5 min (critical)
  velocityMetrics: { ttl: 0, layer: 'NONE' },      // NO CACHE (volatile)
};
```

---

## Alternatives Considered

### Alternative 1: Redis Only (Single Layer)
```typescript
// Pas de L1, uniquement Redis
const data = await redis.get(key) ?? await db.query(...);
```

- **Avantages**: Plus simple, partagÃ© entre instances, pas de cache inconsistency
- **InconvÃ©nients**: Latency constante 5-10ms (vs < 1ms avec L1), sur 1000 req/s = 5-10s de latency cumulÃ©e
- **RejetÃ© car**: Performance pas optimale, L1 apporte 5-10x speedup

### Alternative 2: In-Memory Only (No Redis)
```typescript
// Juste Map en mÃ©moire
const memCache = new Map();
const data = memCache.get(key) ?? await db.query(...);
```

- **Avantages**: Ultra-simple, ultra-rapide (<1ms), zero coÃ»t
- **InconvÃ©nients**: **PAS partagÃ© entre instances serverless**, chaque cold start = cache vide, hit rate faible (30-50%)
- **RejetÃ© car**: Serverless = instances Ã©phÃ©mÃ¨res, besoin de persistance entre instances

### Alternative 3: CDN Edge Cache (Cloudflare KV)
```typescript
// Cache at edge (ultra-distributed)
const data = await env.KV.get(key) ?? await db.query(...);
```

- **Avantages**: Ultra-rapide (<5ms), distribuÃ© mondialement
- **InconvÃ©nients**: Vendor lock-in Cloudflare, nÃ©cessite Cloudflare Workers, eventually consistent (pas ideal pour fraud detection)
- **RejetÃ© car**: On utilise Vercel, pas Cloudflare (mais future option)

---

## Consequences

### Positive
- âœ… **Performance ultime**: L1 hit = < 1ms (90% des cas aprÃ¨s warm-up)
- âœ… **Serverless-friendly**: Redis garde cache chaud entre instances
- âœ… **Hit rate Ã©levÃ©**: Target 80-90% (L1 + L2 combinÃ©s)
- âœ… **Cost-effective**: Upstash Redis = $0-10/mois pour dÃ©marrer
- âœ… **Ã‰volutif**: Peut scale Ã  millions de requÃªtes
- âœ… **Warm-up automatique**: L2 hit repopule L1

### Negative
- âš ï¸ **ComplexitÃ©**: 2 layers Ã  gÃ©rer (set, get, invalidate)
- âš ï¸ **Invalidation dÃ©licate**: Doit invalider L1 ET L2 simultanÃ©ment
- âš ï¸ **CoÃ»t Redis**: $10-30/mois selon usage (mais acceptable)
- âš ï¸ **Stale data possible**: Entre invalidation et propagation (~1-60s)

### Neutral
- ğŸ”„ **Monitoring requis**: Track hit rates par layer (dashboard admin)
- ğŸ”„ **Tuning TTLs**: Ajuster selon usage rÃ©el

---

## Implementation Notes

### 1. Event-Based Invalidation

```typescript
// Invalider cache quand donnÃ©es changent
export async function updateCustomRule(ruleId: string, updates: Partial<CustomRule>) {
  // 1. Update DB
  await db.update(customRules).set(updates).where(eq(customRules.id, ruleId));
  
  // 2. Invalidate cache
  await cache.invalidate(`rules:${rule.organizationId}`);
}

// Invalider sur dispute (customer score change)
export async function handleDisputeCreated(dispute: Stripe.Dispute) {
  await cache.invalidate(`trust:${dispute.charge.customer}`);
}
```

### 2. Cache Key Strategy

```typescript
// Pattern: {type}:{organizationId}:{resourceId?}
const keys = {
  rules: (orgId: OrganizationId) => `rules:${orgId}`,
  trustScore: (customerId: CustomerId) => `trust:${customerId}`,
  whitelist: (orgId: OrganizationId) => `whitelist:${orgId}`,
  blacklist: (orgId: OrganizationId) => `blacklist:${orgId}`,
};
```

### 3. Metrics Dashboard

```typescript
// GET /api/admin/cache/metrics
export async function GET() {
  const stats = cache.getStats();
  return Response.json({
    l1: {
      hits: stats.l1Hits,
      hitRate: stats.l1Hits / (stats.l1Hits + stats.l2Hits + stats.misses),
      size: stats.l1Size,
    },
    l2: {
      hits: stats.l2Hits,
      hitRate: stats.l2Hits / (stats.l2Hits + stats.misses),
    },
    overall: {
      hitRate: (stats.l1Hits + stats.l2Hits) / (stats.l1Hits + stats.l2Hits + stats.misses),
      avgLatency: stats.avgLatency,
    },
  });
}
```

### 4. Upstash Redis Setup

```bash
# Create Upstash Redis instance
# https://upstash.com

# Add to .env
UPSTASH_REDIS_URL=https://xxx.upstash.io
UPSTASH_REDIS_TOKEN=AXX...
```

```typescript
// lib/redis.ts
import { Redis } from '@upstash/redis';

export const redis = new Redis({
  url: process.env.UPSTASH_REDIS_URL!,
  token: process.env.UPSTASH_REDIS_TOKEN!,
});
```

---

## Performance Impact

**Before Cache** :
```
Context Building: 200ms
â”œâ”€ Fetch Custom Rules: 40ms
â”œâ”€ Fetch Customer Score: 30ms
â”œâ”€ Fetch Whitelist: 50ms
â”œâ”€ Fetch Card Data: 40ms
â””â”€ Fetch Velocity: 40ms
```

**After Cache (80% hit rate)** :
```
Context Building: 60ms (average)
â”œâ”€ Custom Rules (L1 hit): 1ms âœ…
â”œâ”€ Customer Score (L2 hit): 8ms âœ…
â”œâ”€ Whitelist (L1 hit): 1ms âœ…
â”œâ”€ Card Data (miss): 40ms
â””â”€ Velocity (no cache): 40ms
```

**Improvement : -70% latency** ğŸ”¥

---

## Related Decisions
- ADR-001: Deployment (Serverless = besoin de L2 persistant)
- ADR-004: Detector Execution (Cache permet early exit ultra-rapide sur blacklist)

---

## Review Schedule
- **2 semaines**: VÃ©rifier hit rates rÃ©els (target: >80%)
- **1 mois**: Analyser coÃ»ts Upstash vs bÃ©nÃ©fice performance
- **3 mois**: Revoir TTLs selon patterns d'usage rÃ©els
